{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planet import api\n",
    "from planet.api import filters\n",
    "from sys import stdout\n",
    "import urllib.request\n",
    "import shutil\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import cv2\n",
    "import glob\n",
    "import subprocess\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import wikipedia\n",
    "from xml.dom import minidom\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your volcano of interest: Anak Krakatoa\n"
     ]
    }
   ],
   "source": [
    "title = input(\"Please input your volcano of interest: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = wikipedia.WikipediaPage(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia summary for your volcano of interest: \n",
      "\n",
      "Anak Krakatoa (English: Child of Krakatoa) is an island in a caldera in the Sunda Strait between the islands of Java and Sumatra in the Indonesian province of Lampung. On December 29, 1927, Anak Krakatoa emerged from the caldera formed in 1883 by the explosive volcanic eruption that destroyed the island of Krakatoa. There has been sporadic eruptive activity at the site since the late 20th century, culminating with a large underwater collapse of the volcano which caused a deadly tsunami in December 2018, followed by subsequent activity in 2019 and an eruption in April 2020. Due to its young age, the island is one of several in the area which are of considerable interest to volcanologists, and the subject of extensive study.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Wikipedia summary for your volcano of interest: \")\n",
    "print(\"\")\n",
    "print(wikipedia.summary(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "References from the wikipedia article of your volcano of interest: \n",
      "\n",
      "[ 1 ] : http://in.reuters.com/article/worldNews/idINIndia-30436520071111?sp=true\n",
      "[ 2 ] : http://portal.vsi.esdm.go.id/joomla/\n",
      "[ 3 ] : http://doi.org/10.1144%2FSP361.7\n",
      "[ 4 ] : http://sp.lyellcollection.org/content/361/1/79\n",
      "[ 5 ] : http://tools.wmflabs.org/geohack/geohack.php?pagename=Anak_Krakatoa&params=6.102_S_105.423_E_type:mountain_scale:100000\n",
      "[ 6 ] : http://www.worldcat.org/issn/0305-8719\n",
      "[ 7 ] : https://www.bbc.com/news/science-environment-46707731\n",
      "[ 8 ] : https://www.nbcnews.com/news/world/indonesia-s-anak-krakatau-volcano-triggered-deadly-tsunami-now-quarter-n952906\n",
      "[ 9 ] : https://www.rt.com/news/441477-tour-boat-fire-bombed-volcano/\n",
      "[ 10 ] : https://www.volcanodiscovery.com/krakatau/news/80657/Krakatau-volcano-Indonesia-activity-update-and-field-report-increasing-unrest.html\n",
      "[ 11 ] : https://www.volcanodiscovery.com/krakatoa/2018/dec/eruption-tsunami/updates.html\n",
      "[ 12 ] : https://volcano.si.edu/volcano.cfm?vn=262000\n",
      "[ 13 ] : https://www.thestar.com.my/news/regional/2018/12/31/number-of-injured-in-indonesia-tsunami-surges-to-over-14000/\n",
      "[ 14 ] : https://www.newshub.co.nz/home/world/2020/04/massive-eruption-at-indonesian-volcano-krakatoa-report.html\n",
      "[ 15 ] : https://web.archive.org/web/20090506120112/http://portal.vsi.esdm.go.id/joomla/\n",
      "[ 16 ] : https://viaf.org/viaf/315128839\n",
      "[ 17 ] : https://www.wikidata.org/wiki/Q2205302\n",
      "[ 18 ] : https://www.bbc.co.uk/news/science-environment-46825354\n",
      "[ 19 ] : https://www.telegraph.co.uk/news/2018/12/22/indonesia-tsunami-least-20-dead-165-injured-waves-hit-beaches/\n"
     ]
    }
   ],
   "source": [
    "print(\"References from the wikipedia article of your volcano of interest: \")\n",
    "print(\"\")\n",
    "\n",
    "References_Wikipedia = page.references\n",
    "\n",
    "len(References_Wikipedia)\n",
    "x = 1\n",
    "\n",
    "for i in References_Wikipedia:\n",
    "    print('[',x,'] :',i)\n",
    "    x = x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Related wikipedia articles to your volcano of interest: \n",
      "\n",
      "[ 1 ] : Krakatoa archipelago - https://en.wikipedia.org/wiki/Krakatoa_archipelago\n",
      "[ 2 ] : Anak Krakatoa - https://en.wikipedia.org/wiki/Anak_Krakatoa\n",
      "[ 3 ] : Krakatoa - https://en.wikipedia.org/wiki/Krakatoa\n",
      "[ 4 ] : 1883 eruption of Krakatoa - https://en.wikipedia.org/wiki/1883_eruption_of_Krakatoa\n",
      "[ 5 ] : 2018 Sunda Strait tsunami - https://en.wikipedia.org/wiki/2018_Sunda_Strait_tsunami\n"
     ]
    }
   ],
   "source": [
    "print(\"Related wikipedia articles to your volcano of interest: \")\n",
    "print(\"\")\n",
    "\n",
    "Related_Wikipedia = wikipedia.geosearch(page.coordinates[0], page.coordinates[1])\n",
    "\n",
    "len(Related_Wikipedia)\n",
    "x = 1\n",
    "\n",
    "for i in Related_Wikipedia:\n",
    "    print ('[',x,'] :', i, '-', wikipedia.page(i).url)\n",
    "    x = x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = float(page.coordinates[0])\n",
    "long = float(page.coordinates[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your start date (YYYY-MM-DD): 2018-12-15\n"
     ]
    }
   ],
   "source": [
    "start_date = input(\"Please input your start date (YYYY-MM-DD): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your end date (YYYY-MM-DD): 2018-12-18\n"
     ]
    }
   ],
   "source": [
    "end_date = input(\"Please input your end date (YYYY-MM-DD): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the percent of maximum cloud cover you want to allow in each image as an integer between 0 and 1 (e.g. 20% = 0.2): 0.2\n"
     ]
    }
   ],
   "source": [
    "cloud_cover = input(\"Please input the percent of maximum cloud cover you want to allow in each image as an integer between 0 and 1 (e.g. 20% = 0.2): \")\n",
    "cloud_cover = float(cloud_cover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input you Planet API key: 219bc2e637384268a2d606dd8c05e7a7\n"
     ]
    }
   ],
   "source": [
    "api_key = input(\"Please input you Planet API key: \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = api.ClientV1(api_key) \n",
    "PL_API_KEY = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_json_geometry = {\n",
    "  \"type\": \"Polygon\",\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              long - 0.07,\n",
    "              lat + 0.07\n",
    "            ],\n",
    "            [\n",
    "              long + 0.07,\n",
    "              lat + 0.07\n",
    "            ],\n",
    "            [\n",
    "              long + 0.07,\n",
    "              lat - 0.07\n",
    "            ],\n",
    "            [\n",
    "              long - 0.07,\n",
    "              lat - 0.07\n",
    "            ],\n",
    "            [\n",
    "              long - 0.07,\n",
    "              lat + 0.07\n",
    "            ]\n",
    "          ]\n",
    "        ]\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_filter = {\n",
    "    \"type\": \"GeometryFilter\",\n",
    "    \"field_name\": \"geometry\",\n",
    "    \"config\": geo_json_geometry\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_filter = {\n",
    "    \"type\": \"DateRangeFilter\",\n",
    "    \"field_name\": \"acquired\",\n",
    "    \"config\": {\n",
    "        \"gte\": start_date + \"T00:00:00.000Z\",\n",
    "        \"lte\": end_date + \"T00:00:00.000Z\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_cover_filter = {\n",
    "    \"type\": \"RangeFilter\",\n",
    "    \"field_name\": \"cloud_cover\",\n",
    "    \"config\": {\n",
    "        \"lte\": cloud_cover,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_types = ['PSScene4Band']\n",
    "asset_type = 'analytic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"type\": \"AndFilter\",\n",
    "    \"config\": [geometry_filter, date_range_filter, cloud_cover_filter]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = filters.build_search_request(\n",
    "    query, item_types\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,cloud_cover,date\n"
     ]
    }
   ],
   "source": [
    "dataset = client.quick_search(request)\n",
    "\n",
    "stdout.write('id,cloud_cover,date\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181217_025142_101e,0.01,2018-12-17T02:51:42.296592Z\n",
      "20181217_025144_101e,0.01,2018-12-17T02:51:44.363859Z\n",
      "20181217_025143_101e,0.01,2018-12-17T02:51:43.330487Z\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.items_iter(limit=None):\n",
    "    props = item['properties']\n",
    "    stdout.write('{0},{cloud_cover},{acquired}\\n'.format(item['id'], **props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSScene4Band\n",
      "20181217_025142_101e\n",
      "204\n",
      "20181217_025144_101e\n",
      "204\n",
      "20181217_025143_101e\n",
      "204\n"
     ]
    }
   ],
   "source": [
    "for i in item_types:\n",
    "    request = api.filters.build_search_request(query, [i])  # ,name = None, interval= 'day')\n",
    "    dataset = client.quick_search(request)\n",
    "    print(i)\n",
    "    for item in dataset.items_iter(limit=50):\n",
    "        print(item['id'])\n",
    "        session = requests.Session()\n",
    "        session.auth = (PL_API_KEY, '')\n",
    "        results = \\\n",
    "            session.get(\n",
    "                (\"https://api.planet.com/data/v1/item-types/\" +\n",
    "                 \"{}/items/{}/assets/\").format(i, item['id']))\n",
    "       \n",
    "        item_activation_url = results.json()[asset_type][\"_links\"][\"activate\"]\n",
    "       \n",
    "        response = session.post(item_activation_url)\n",
    "        print(response.status_code)\n",
    "        while response.status_code != 204:\n",
    "            time.sleep(30)\n",
    "            response = session.post(item_activation_url)\n",
    "            response.status_code = response.status_code\n",
    "            print(response.status_code)\n",
    "        \n",
    "        item_url = 'https://api.planet.com/data/v1/item-types/{}/items/{}/assets'.format(i, item['id'])\n",
    "        result = requests.get(item_url, auth=HTTPBasicAuth(PL_API_KEY, ''))\n",
    "        download_url = result.json()[asset_type]['location']  # KeyError: 'location'\n",
    "        output_file = item['id'] + '.tif'\n",
    "\n",
    "        with urllib.request.urlopen(download_url) as response, open(output_file, 'wb') as out_file:\n",
    "            shutil.copyfileobj(response, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_types2 = ['PSScene4Band']\n",
    "asset_type2 = 'analytic_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"type\": \"AndFilter\",\n",
    "    \"config\": [geometry_filter, date_range_filter, cloud_cover_filter]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = filters.build_search_request(\n",
    "    query, item_types2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,cloud_cover,date\n"
     ]
    }
   ],
   "source": [
    "dataset = client.quick_search(request)\n",
    "\n",
    "stdout.write('id,cloud_cover,date\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181217_025142_101e,0.01,2018-12-17T02:51:42.296592Z\n",
      "20181217_025144_101e,0.01,2018-12-17T02:51:44.363859Z\n",
      "20181217_025143_101e,0.01,2018-12-17T02:51:43.330487Z\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.items_iter(limit=None):\n",
    "    props = item['properties']\n",
    "    stdout.write('{0},{cloud_cover},{acquired}\\n'.format(item['id'], **props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSScene4Band\n",
      "20181217_025142_101e\n",
      "204\n",
      "20181217_025144_101e\n",
      "204\n",
      "20181217_025143_101e\n",
      "204\n"
     ]
    }
   ],
   "source": [
    "for i in item_types2:\n",
    "    request = api.filters.build_search_request(query, [i])  # ,name = None, interval= 'day')\n",
    "    dataset = client.quick_search(request)\n",
    "    print(i)\n",
    "    for item in dataset.items_iter(limit=50):\n",
    "        print(item['id'])\n",
    "        session = requests.Session()\n",
    "        session.auth = (PL_API_KEY, '')\n",
    "        results = \\\n",
    "            session.get(\n",
    "                (\"https://api.planet.com/data/v1/item-types/\" +\n",
    "                 \"{}/items/{}/assets/\").format(i, item['id']))\n",
    "       \n",
    "        item_activation_url = results.json()[asset_type2][\"_links\"][\"activate\"]\n",
    "       \n",
    "        response = session.post(item_activation_url)\n",
    "        print(response.status_code)\n",
    "        while response.status_code != 204:\n",
    "            time.sleep(30)\n",
    "            response = session.post(item_activation_url)\n",
    "            response.status_code = response.status_code\n",
    "            print(response.status_code)\n",
    "        \n",
    "        item_url = 'https://api.planet.com/data/v1/item-types/{}/items/{}/assets'.format(i, item['id'])\n",
    "        result = requests.get(item_url, auth=HTTPBasicAuth(PL_API_KEY, ''))\n",
    "        download_url = result.json()[asset_type2]['location']  # KeyError: 'location'\n",
    "        output_file = item['id'] + '.xml'\n",
    "\n",
    "        with urllib.request.urlopen(download_url) as response, open(output_file, 'wb') as out_file:\n",
    "            shutil.copyfileobj(response, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.mkdir('Original_Imagery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = os.getcwd()\n",
    "sf = os.listdir(sp)\n",
    "dp = sp + ('\\\\Original_Imagery')\n",
    "for file in sf:\n",
    "    if file.endswith(('.tif','.xml')):\n",
    "        shutil.move(os.path.join(sp,file), os.path.join(dp, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [f for f in os.listdir(dp) if os.path.isfile(os.path.join(dp, f))]\n",
    "\n",
    "for image in images:\n",
    "    folder_name = image.split('_')[0]\n",
    "\n",
    "    new_path = os.path.join(dp, folder_name)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.makedirs(new_path)\n",
    "\n",
    "    old_image_path = os.path.join(dp, image)\n",
    "    new_image_path = os.path.join(new_path, image)\n",
    "    shutil.move(old_image_path, new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python C:\\Users\\maddi\\Downloads\\PlanetCode-Integration-and-sorting-patch-3\\PlanetCode-Integration-and-sorting-patch-3\\gdal_merge.py -o 20181217.tif -of gtiff C:\\Users\\maddi\\Downloads\\PlanetCode-Integration-and-sorting-patch-3\\PlanetCode-Integration-and-sorting-patch-3\\Original_Imagery\\20181217\\20181217_025142_101e.tif C:\\Users\\maddi\\Downloads\\PlanetCode-Integration-and-sorting-patch-3\\PlanetCode-Integration-and-sorting-patch-3\\Original_Imagery\\20181217\\20181217_025143_101e.tif C:\\Users\\maddi\\Downloads\\PlanetCode-Integration-and-sorting-patch-3\\PlanetCode-Integration-and-sorting-patch-3\\Original_Imagery\\20181217\\20181217_025144_101e.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "folders = []\n",
    "for r, d, f in os.walk(dp):\n",
    "    for folder in d:\n",
    "        folders.append(os.path.join(r, folder))\n",
    "\n",
    "i = 0\n",
    "for x in folders:\n",
    "    files_to_mosaic = glob.glob(folders[i] + '/*.tif')\n",
    "    files_string = \" \".join(files_to_mosaic)\n",
    "    command = \"python \" + sp + \"\\gdal_merge.py -o \"+ files_string[-33:-25] + \".tif\" + \" -of gtiff \" + files_string\n",
    "    print(command)\n",
    "    i = i + 1\n",
    "    output = subprocess.getoutput(command)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('Merged_Tifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp2 = os.getcwd()\n",
    "sf2 = os.listdir(sp2)\n",
    "dp2 = sp2 + ('\\\\Merged_Tifs')\n",
    "for file in sf2:\n",
    "    if file.endswith(('.tif','.xml')):\n",
    "        shutil.move(os.path.join(sp2,file), os.path.join(dp2, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(sp2 + '\\\\Merged_Tifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for r, d, f in os.walk(dp2):\n",
    "    for file in f:\n",
    "        files.append(os.path.join(r, file))\n",
    "        \n",
    "timeavg = []\n",
    "ndviavg = []\n",
    "\n",
    "i = 0\n",
    "for x in files:\n",
    "    with rasterio.open(files[i]) as src:\n",
    "            band_red = src.read(3)\n",
    "    with rasterio.open(files[i]) as src:\n",
    "            band_nir = src.read(4)       \n",
    "            \n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    ndvi = ((band_nir.astype(float) - band_red.astype(float)) / (band_nir.astype(float) + band_red.astype(float)))\n",
    "    \n",
    "    \n",
    "    kwargs = src.meta\n",
    "    kwargs.update(\n",
    "    dtype = rasterio.float32,\n",
    "    count = 1)\n",
    "    with rasterio.open('ndvi_' + f[i], 'w', **kwargs) as dst:\n",
    "        dst.write_band(1, ndvi.astype(rasterio.float32))\n",
    "        \n",
    "    ndvi2 = np.ma.masked_where(ndvi < 0., ndvi)\n",
    "    \n",
    "    fig2 = plt.figure(figsize=(10,10))\n",
    "    ax = fig2.add_subplot(111)\n",
    "    \n",
    "    plt.title(f[i] + \" NDVI Histogram\", fontsize=18, fontweight='bold')\n",
    "    plt.xlabel(\"NDVI values\", fontsize=14)\n",
    "    plt.ylabel(\"# pixels\", fontsize=14)\n",
    "    \n",
    "    b = ndvi2[~np.isnan(ndvi2)]\n",
    "    numBins = 20\n",
    "    ax.hist(b,numBins,color='blue',alpha=0.8)\n",
    "    ax.set_xlim([0, 1])\n",
    "    fig2.savefig(\"ndvi_\" + f[i][0:8] + \"_histogram.png\", dpi=200, bbox_inches='tight', pad_inches=0.7)\n",
    "\n",
    "    \n",
    "    ndvi_adjusted = ndvi * (-255.0)\n",
    "    masked_ndvi_adjusted = np.ma.array(ndvi_adjusted, mask=np.isnan(ndvi_adjusted))\n",
    "    cmap = plt.cm.RdYlGn\n",
    "    cmap.set_bad(color = 'white',alpha = 0.0)\n",
    "    img = masked_ndvi_adjusted.astype(np.uint8)\n",
    "    plt.imsave(\"ndvi_\" + f[i][0:8] + \"_colormap.tiff\", img, cmap=cmap)\n",
    "    plt.close()\n",
    "    \n",
    "    avg = np.average(b)\n",
    "    ndviavg.append(avg)\n",
    "    time = f[i][4:8]\n",
    "    timeavg.append(time)\n",
    "       \n",
    "    i = i + 1\n",
    "    \n",
    "fig3 = plt.figure(figsize=(10,10))\n",
    "ax2 = fig3.add_subplot(111)\n",
    "ax2.set_ylim([0, 1])\n",
    "plt.plot(timeavg, ndviavg, color = 'blue', linewidth = 4)\n",
    "plt.axhspan(0, 0.3, facecolor='r', alpha = 0.5, label = 'Below: Unhealthy')\n",
    "plt.axhspan(0.3, 0.6, facecolor='y', alpha = 0.5, label = 'Below: Somewhat Healthy')\n",
    "plt.axhspan(0.6, 1, facecolor='g', alpha = 0.5, label = 'Above: Healthy')\n",
    "plt.legend()\n",
    "plt.title(\"Average NDVI Over Time\", fontsize=18, fontweight='bold')\n",
    "plt.xlabel(\"Start Date & End Date\", fontsize=14)\n",
    "plt.ylabel(\"Average NDVI\", fontsize=14)\n",
    "fig3.savefig(\"AverageNDVI_OverTime.png\", dpi=200, bbox_inches='tight', pad_inches=0.7)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp3 = os.getcwd()\n",
    "sf3 = os.listdir(sp3)\n",
    "\n",
    "for file in sf3:\n",
    "    if file.startswith('ndvi'):\n",
    "        shutil.move(os.path.join(sp3,file), os.path.join(sp2,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(sp2)\n",
    "os.mkdir('Vegetation_Indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp4 = os.getcwd()\n",
    "sf4 = os.listdir(sp4)\n",
    "dp4 = sp2 + '\\\\Vegetation_Indices'\n",
    "\n",
    "for file in sf3:\n",
    "    if file.startswith('ndvi'):\n",
    "        shutil.move(os.path.join(sp4,file), os.path.join(dp4,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Merged_Tifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp3 = os.getcwd()\n",
    "sf3 = os.listdir(sp3)\n",
    "\n",
    "for file in sf3:\n",
    "    if file.startswith('Ave'):\n",
    "        shutil.move(os.path.join(sp3,file), os.path.join(sp2,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(sp2)\n",
    "os.mkdir('Average_NDVI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp4 = os.getcwd()\n",
    "sf4 = os.listdir(sp4)\n",
    "dp4 = sp2 + '\\\\Average_NDVI'\n",
    "\n",
    "for file in sf3:\n",
    "    if file.startswith('Ave'):\n",
    "        shutil.move(os.path.join(sp4,file), os.path.join(dp4,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(sp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_types = ['PSScene3Band']\n",
    "asset_type = 'visual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"type\": \"AndFilter\",\n",
    "    \"config\": [geometry_filter, date_range_filter, cloud_cover_filter]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = filters.build_search_request(\n",
    "    query, item_types\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,cloud_cover,date\n"
     ]
    }
   ],
   "source": [
    "dataset = client.quick_search(request)\n",
    "\n",
    "stdout.write('id,cloud_cover,date\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181217_025142_101e,0.01,2018-12-17T02:51:42.296592Z\n",
      "20181217_025143_101e,0.01,2018-12-17T02:51:43.330487Z\n",
      "20181217_025144_101e,0.01,2018-12-17T02:51:44.363859Z\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.items_iter(limit=None):\n",
    "    props = item['properties']\n",
    "    stdout.write('{0},{cloud_cover},{acquired}\\n'.format(item['id'], **props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSScene3Band\n",
      "20181217_025142_101e\n",
      "204\n",
      "20181217_025143_101e\n",
      "204\n",
      "20181217_025144_101e\n",
      "204\n"
     ]
    }
   ],
   "source": [
    "for i in item_types:\n",
    "    request = api.filters.build_search_request(query, [i])  # ,name = None, interval= 'day')\n",
    "    dataset = client.quick_search(request)\n",
    "    print(i)\n",
    "    for item in dataset.items_iter(limit=100):\n",
    "        print(item['id'])\n",
    "        session = requests.Session()\n",
    "        session.auth = (PL_API_KEY, '')\n",
    "        results = \\\n",
    "            session.get(\n",
    "                (\"https://api.planet.com/data/v1/item-types/\" +\n",
    "                 \"{}/items/{}/assets/\").format(i, item['id']))\n",
    "       \n",
    "        item_activation_url = results.json()[asset_type][\"_links\"][\"activate\"]\n",
    "       \n",
    "        response = session.post(item_activation_url)\n",
    "        print(response.status_code)\n",
    "        while response.status_code != 204:\n",
    "            time.sleep(30)\n",
    "            response = session.post(item_activation_url)\n",
    "            response.status_code = response.status_code\n",
    "            print(response.status_code)\n",
    "        \n",
    "        item_url = 'https://api.planet.com/data/v1/item-types/{}/items/{}/assets'.format(i, item['id'])\n",
    "        result = requests.get(item_url, auth=HTTPBasicAuth(PL_API_KEY, ''))\n",
    "        download_url = result.json()[asset_type]['location']  # KeyError: 'location'\n",
    "        output_file = item['id'] + '.tif'\n",
    "\n",
    "        with urllib.request.urlopen(download_url) as response, open(output_file, 'wb') as out_file:\n",
    "            shutil.copyfileobj(response, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('Original_Ash_Imagery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp5 = os.getcwd()\n",
    "sf5 = os.listdir(sp5)\n",
    "dp5 = sp5 + ('\\\\Original_Ash_Imagery')\n",
    "for file in sf5:\n",
    "    if file.endswith('.tif'):\n",
    "        shutil.move(os.path.join(sp5,file), os.path.join(dp5, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [f for f in os.listdir(dp5) if os.path.isfile(os.path.join(dp5, f))]\n",
    "\n",
    "for image in images:\n",
    "    folder_name = image.split('_')[0]\n",
    "\n",
    "    new_path = os.path.join(dp5, folder_name)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.makedirs(new_path)\n",
    "\n",
    "    old_image_path = os.path.join(dp5, image)\n",
    "    new_image_path = os.path.join(new_path, image)\n",
    "    shutil.move(old_image_path, new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python C:\\Users\\maddi\\Downloads\\PlanetCode-Integration-and-sorting-patch-3\\PlanetCode-Integration-and-sorting-patch-3\\gdal_merge.py -o 20181217.tif -of gtiff C:\\Users\\maddi\\Downloads\\PlanetCode-Integration-and-sorting-patch-3\\PlanetCode-Integration-and-sorting-patch-3\\Original_Ash_Imagery\\20181217\\20181217_025142_101e.tif C:\\Users\\maddi\\Downloads\\PlanetCode-Integration-and-sorting-patch-3\\PlanetCode-Integration-and-sorting-patch-3\\Original_Ash_Imagery\\20181217\\20181217_025143_101e.tif C:\\Users\\maddi\\Downloads\\PlanetCode-Integration-and-sorting-patch-3\\PlanetCode-Integration-and-sorting-patch-3\\Original_Ash_Imagery\\20181217\\20181217_025144_101e.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "folders = []\n",
    "for r, d, f in os.walk(dp5):\n",
    "    for folder in d:\n",
    "        folders.append(os.path.join(r, folder))\n",
    "\n",
    "i = 0\n",
    "for x in folders:\n",
    "    files_to_mosaic = glob.glob(folders[i] + '/*.tif')\n",
    "    files_string = \" \".join(files_to_mosaic)\n",
    "    command = \"python \" + sp5 + \"\\gdal_merge.py -o \"+ files_string[-33:-25] + \".tif\" + \" -of gtiff \" + files_string\n",
    "    print(command)\n",
    "    i = i + 1\n",
    "    output = subprocess.getoutput(command)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('Merged_Ash_Tifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp6 = os.getcwd()\n",
    "sf6 = os.listdir(sp5)\n",
    "dp6 = sp6 + ('\\\\Merged_Ash_Tifs')\n",
    "for file in sf6:\n",
    "    if file.endswith('.tif'):\n",
    "        shutil.move(os.path.join(sp6,file), os.path.join(dp6, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dp6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = [i for i in dir(cv2) if i.startswith('COLOR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "range1_lo = (130, 130, 89, 255)\n",
    "range1_hi = (166, 152, 129, 255)\n",
    "\n",
    "range2_lo = (153, 146, 137, 255)\n",
    "range2_hi = (219, 208, 195, 255)\n",
    "\n",
    "range3_lo = (120, 119, 114, 255)\n",
    "range3_hi = (125, 126, 121, 255)\n",
    "\n",
    "range4_lo = (144, 144, 129, 255)\n",
    "range4_hi = (150, 150, 137, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for r, d, f in os.walk(dp6):\n",
    "    for file in f:\n",
    "        files.append(os.path.join(r, file))\n",
    "\n",
    "ash_pixels = []\n",
    "timeavg = []\n",
    "\n",
    "i = 0\n",
    "for x in files:\n",
    "    img = cv2.imread(files[i])\n",
    "    img2 = cv2.cvtColor(img, cv2.COLOR_BGRA2RGBA)\n",
    "    \n",
    "    mask_range1 = cv2.inRange(img2, range1_lo, range1_hi)\n",
    "    mask_range2 = cv2.inRange(img2, range2_lo, range2_hi)\n",
    "    mask_range3 = cv2.inRange(img2, range3_lo, range3_hi)\n",
    "    mask_range4 = cv2.inRange(img2, range4_lo, range4_hi)\n",
    "    \n",
    "    ash_mask = mask_range1+mask_range2+mask_range3+mask_range4\n",
    "    ash_result = cv2.bitwise_and(img2, img2, mask=ash_mask)\n",
    "    \n",
    "    img[ash_mask>0]=(0,0,255)\n",
    "    cv2.imwrite('Ash_Overlay_' + f[i] + '.tif', img)\n",
    "    \n",
    "    pixel_count = cv2.countNonZero(ash_mask)\n",
    "    ash_pixels.append(pixel_count)\n",
    "    \n",
    "    time = f[i][4:8]\n",
    "    timeavg.append(time)\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "fig3 = plt.figure(figsize=(10,10))\n",
    "ax2 = fig3.add_subplot(111)\n",
    "plt.plot(timeavg, ash_pixels, color = 'blue', linewidth = 4)\n",
    "plt.title(\"Ash Coverage Over Time\", fontsize=18, fontweight='bold')\n",
    "plt.xlabel(\"Start Date & End Date\", fontsize=14)\n",
    "plt.ylabel(\"# of Pixels\", fontsize=14)\n",
    "fig3.savefig(\"Ash_Coverage_OverTime.png\", dpi=200, bbox_inches='tight', pad_inches=0.7)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp7 = os.getcwd()\n",
    "sf7 = os.listdir(sp7)\n",
    "\n",
    "for file in sf7:\n",
    "    if file.startswith('Ash'):\n",
    "        shutil.move(os.path.join(sp7,file), os.path.join(sp2,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(sp2)\n",
    "os.mkdir('Segmentation_Ash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp8 = os.getcwd()\n",
    "sf8 = os.listdir(sp8)\n",
    "dp8 = sp2 + '\\\\Segmentation_Ash'\n",
    "\n",
    "for file in sf8:\n",
    "    if file.startswith('Ash'):\n",
    "        shutil.move(os.path.join(sp8,file), os.path.join(dp8,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to make a new folder to store data? y/n: y\n",
      "Enter new folder name: Poop\n"
     ]
    }
   ],
   "source": [
    "newfldr = input('Would you like to make a new folder to store data? y/n: ')\n",
    "\n",
    "if newfldr == 'n':\n",
    "    print('Goodbye')\n",
    "elif newfldr == 'y':\n",
    "    nf = os.mkdir(input('Enter new folder name: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp9 = os.getcwd()\n",
    "sf9 = os.listdir(sp9)\n",
    "dp9 = sp2 + nf\n",
    "\n",
    "for folder in sf9:\n",
    "    if folder.startswith(('Ave', 'Mer', 'Ori', 'Seg', 'Veg')):\n",
    "        shutil.move(os.path.join(sp9,folder), os.path.join(dp9, folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to move your new folder to Desktop? y/n: y\n",
      "Folder Moved\n"
     ]
    }
   ],
   "source": [
    "move = input('Would you like to move your new folder to Desktop? y/n: ')\n",
    "\n",
    "if move == 'n':\n",
    "    print('Folder Not Moved')\n",
    "elif move == 'y':\n",
    "    sp10 = os.getcwd()\n",
    "    sf10 = os.listdir(sp10)\n",
    "    dp10 = '\\\\Desktop'\n",
    "    shutil.move(os.path.join(sp10,nf), os.path.join(dp10, nf))\n",
    "    print('Folder Moved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to run another dataset? y/n: n\n",
      "Have fun\n"
     ]
    }
   ],
   "source": [
    "restart = input('Would you like to run another dataset? y/n: ')\n",
    "\n",
    "if restart == 'n':\n",
    "    print('Have fun')\n",
    "    pass\n",
    "elif restart == 'y':\n",
    "    os.execl(sys.executable, '\"{}\"'.format(sys.executable), *sys.argv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
